1. 神经网络
    1. ReLU函数 修正线性单元
    2. 将不同神经元堆叠而成即形成神经网络
    3. 我们只需要想神经网络输入数据，通过对输入隐藏的神经节点，得到输出结果
    4. 我们需要大量的数据区监督学习该模型使之能够正确输出
    5. 监督学习是神经网络构建的关键
2. 二分分类
    1. logistic回归是一个用于二分分类的算法
    2. logistic的损失函数推荐用L(y`,y)=-(ylogy`+(1-y)log(1-y`))
    3. 根据损失函数即可定义一个成本函数
    4. 通过梯度下降法迭代即可求得局部最优解，由于logistic回归的特殊性，局部最优即全局最优，这页解释了2
    5. 向量化
        1. 可以消除代码中的显示for循环，并且增加效率
        2. 原理是CPU或GPU可以采用并行化指令
        3. 需要注意由于python的广播性质，尽管带来了一些便利但，要注意两个以为矩阵相乘时应该指明矩阵纬度以避免广播引起的bug